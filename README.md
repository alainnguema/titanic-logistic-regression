# Titanic Survival Prediction - Logistic Regression from Scratch

ImplÃ©mentation manuelle de la rÃ©gression logistique multivariÃ©e pour prÃ©dire la survie des passagers du Titanic.

## ğŸ“‹ Description

Ce projet implÃ©mente une rÃ©gression logistique multivariÃ©e **from scratch** (sans utiliser de bibliothÃ¨ques de machine learning comme scikit-learn) pour prÃ©dire si un passager du Titanic a survÃ©cu ou non. Le modÃ¨le est entraÃ®nÃ© sur le dataset Titanic en utilisant uniquement NumPy et Pandas.

## ğŸ¯ FonctionnalitÃ©s

- **PrÃ©processing des donnÃ©es** :
  - Gestion des valeurs manquantes (Age, Embarked)
  - Transformation des variables catÃ©gorielles (Sex, Ticket, Embarked) en variables binaires (one-hot encoding)
  - Normalisation des caractÃ©ristiques numÃ©riques

- **ImplÃ©mentation de la rÃ©gression logistique** :
  - Fonction hypothÃ¨se (sigmoid)
  - Fonction de coÃ»t (log-likelihood)
  - Calcul du gradient
  - Descente de gradient pour l'optimisation

- **Ã‰valuation** :
  - Calcul de la prÃ©cision (accuracy)
  - Suivi du coÃ»t pendant l'entraÃ®nement

## ğŸ“¦ DÃ©pendances

```bash
numpy >= 1.20.0
pandas >= 1.3.0
matplotlib >= 3.3.0
jupyter >= 1.0.0
```

## ğŸš€ Installation

1. Clonez le repository :
```bash
git clone https://github.com/votre-username/titanic-logistic-regression.git
cd titanic-logistic-regression
```

2. Installez les dÃ©pendances :
```bash
pip install numpy pandas matplotlib jupyter
```

3. TÃ©lÃ©chargez les donnÃ©es :
   - Placez les fichiers `train.csv` et `test.csv` du dataset Titanic dans le rÃ©pertoire du projet
   - Les donnÃ©es sont disponibles sur [Kaggle](https://www.kaggle.com/c/titanic/data)

## ğŸ“Š Utilisation

1. Ouvrez le notebook Jupyter :
```bash
jupyter notebook multivariate_logistic_regression.ipynb
```

2. ExÃ©cutez toutes les cellules pour :
   - Charger et explorer les donnÃ©es
   - PrÃ©parer les donnÃ©es (nettoyage, transformation)
   - EntraÃ®ner le modÃ¨le de rÃ©gression logistique
   - Ã‰valuer les performances

## ğŸ“ˆ RÃ©sultats

Le modÃ¨le atteint une prÃ©cision d'environ **79%** sur l'ensemble d'entraÃ®nement aprÃ¨s 100,000 itÃ©rations avec un taux d'apprentissage de 0.001.

## ğŸ”§ Structure du Code

- **PrÃ©processing** : SÃ©lection des caractÃ©ristiques, gestion des valeurs manquantes, encodage one-hot
- **Normalisation** : Normalisation min-max des caractÃ©ristiques numÃ©riques
- **Fonctions du modÃ¨le** :
  - `hypothesis(X, theta)` : Calcule la probabilitÃ© de survie
  - `cost(X, Y, theta)` : Calcule la fonction de coÃ»t (log-likelihood)
  - `gradient(X, Y, theta)` : Calcule le gradient
  - `gradient_descent(X, Y, lr, steps)` : EntraÃ®ne le modÃ¨le
  - `accuracy(X, Y, theta)` : Calcule la prÃ©cision

## ğŸ“ CaractÃ©ristiques UtilisÃ©es

- **Pclass** : Classe du passager (1, 2, 3)
- **Sex** : Sexe (male, female)
- **Age** : Ã‚ge
- **SibSp** : Nombre de frÃ¨res/sÅ“urs/Ã©poux Ã  bord
- **Parch** : Nombre de parents/enfants Ã  bord
- **Ticket** : CatÃ©gorie du ticket (transformÃ©e)
- **Fare** : Prix du billet
- **Embarked** : Port d'embarquement (C, Q, S)

## ğŸ“ Apprentissage

Ce projet est conÃ§u Ã  des fins Ã©ducatives pour comprendre :
- Le fonctionnement interne de la rÃ©gression logistique
- L'implÃ©mentation de l'algorithme de descente de gradient
- Le preprocessing des donnÃ©es pour le machine learning
- L'Ã©valuation des modÃ¨les de classification

## ğŸ“„ Licence

Ce projet est libre d'utilisation Ã  des fins Ã©ducatives.

## ğŸ‘¤ Auteur

Projet rÃ©alisÃ© dans le cadre du cours d'Automatisation SupervisÃ©e (Supervised Learning)

---

**Note** : Les fichiers `train.csv` et `test.csv` ne sont pas inclus dans le repository. Veuillez les tÃ©lÃ©charger depuis [Kaggle](https://www.kaggle.com/c/titanic/data).

